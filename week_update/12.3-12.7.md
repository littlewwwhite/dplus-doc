## agent：
agent 教程：[长文ReAct原理揭秘：密OpenAI GPT和LangChain中的ReAct（Reason+Act）提示](https://mp.weixin.qq.com/s/f-iYhuLcV-O4KD1XS-q2fw)
langchain-agent： [ReAct | 🦜️🔗 Langchain](https://python.langchain.com/docs/modules/agents/agent_types/react)
agent 的使用比单纯的构建一个向量知识库更加的灵活和有更高的应用上限，目前普遍使用的是上面所说的 react 的架构。

### agent 的使用方式之一：九章云极 tableagent 在线试用：[TableAgent](https://tableagent.datacanvas.com/tableagent)
上面的TableAgent我觉得完全可以作为接下来的主要改进方向之一。


## 量化
AWQ 量化： [mit-han-lab/llm-awq: AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration](https://github.com/mit-han-lab/llm-awq)
GPTQ 详细教程：[使用 AutoGPTQ 和 transformers 让大语言模型更轻量化](https://huggingface.co/blog/zh/gptq-integration)

其实上述量化都已经被融入到下面的推理框架中了，而且一般量化模型的代价都比较大。所以我们只要熟悉了推理框架是如何使用量化版本的模型就足够了。

## 推理架构
vLLM：[vllm-project/vllm: A high-throughput and memory-efficient inference and serving engine for LLMs](https://github.com/vllm-project/vllm)
vLLM 需要 cuda12.0+和 pytorch2.0+

LMDeploy：[InternLM/lmdeploy: LMDeploy is a toolkit for compressing, deploying, and serving LLMs.](https://github.com/InternLM/lmdeploy)
这个也是个比较常用的推理框架

fastchat：[lm-sys/FastChat: An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and Chatbot Arena.](https://github.com/lm-sys/FastChat)
用于快速验证模型性能很有用，支持 API 接口多模型部署。

## other
**关于目前的项目的改进点：（也是为什么需要 agent 的原因）**
### 1.RAG 的缺陷：

【一】 **世界知识和领域知识混淆**

```
提问：乙烯和丙烯的关系是什么？
```

大模型应该回答两者都属于有机化合物，还是根据近期产业资讯回答，两者的价格均在上涨？
要做好这个需要数据过滤单元分辨

【二】 **召回结果混淆**

```
提问：xx行业关注度排名第几？
```

当 xx 范围较大，问题和很多内容都相似度高会召回很多不想干文档。

【三】 **多条件约束失效**  

```
提问：昨天《独家新闻》统计的化学制品行业的关注度排名第几？
```

如果说【二】中的约束太少导致召回结果过于泛滥，那么我加上约束之后，如何让大模型读懂什么叫 “昨天”，又有哪段内容属于《独家新闻》？

【四】 **全文 / 多文类意图失效**

```
提问：近期《独家新闻》系列文章对哪些行业关注度最高？
```

受限于文档切割，遇到横跨多篇文章，或全篇文章的提问，基本上无法处理。

【五】 **复杂逻辑推理**

```
提问：近期当乙烯和丙烯同时下跌的时候，哪个在上涨？
```

除非原文中有显性且密集型相关内容，大模型可能能够直接回答正确，否则出错概率极高。而用户在提问这类问题时，往往是无法在某一段落中直接找到答案的，需要深层次推理。

【六】 **实时计算**

```
提问：昨天哪些股票发生了涨停？
```

如何让大模型理解 “涨停” 意味着 (收盘价 / 昨日收盘价 - 1)≥10%


要想完整的解决上述 RAG 所面临的问题，agent 我认为是必不可少的。


### 2. 如何改进当前的 NL2Cypher

相较于直接 NL2Cypher，我认为需要再加一个中间层（领域特殊语言），也就是先 NL2DSL，再 DSL2Cypher。

提出这个想法的主要原因是直接 NL2Cypher 很多时候其实很多时候场景无法准确覆盖，会有很多问题产生，遇到派生词如何解决，遇到复杂逻辑又如何解决？等等复杂领域问题单纯的 NL2Cypher 是无法应对的，所以当加入一个中间层。我们只是做翻译，也就是让大模型（通过 prompt 和微调即可）将 “文本” 翻译成我们希望得到的一段结构化表达式，可能是 json，可能是 xml。当得到这些领域形的结构化数据以后，再将其转换为 Cypher 语句来做查询即可，准确率更高。